{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"CDP_2_fasea_Ikasle.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"jkBSUy-YmkZX"},"source":["## 2. Fasea: Algoritmoak diseinatzen"]},{"cell_type":"markdown","metadata":{"id":"AI4cqWvNmkZZ"},"source":["#### Julen Etxaniz eta Aitor Zubillaga\n","\n","Community Detection proiektuaren 1. fasea entregatu duzue, eta feedback-a jaso ere. Klasean hainbat algoritmo ikusi ditugu, batzuk soluzio bakarrean oinarritutakoak, beste batzuk aldiz, populazio bat erabiltzen dutenak. Horiez gain, hibridatzeko teknikak ere ikusi ditugu. Bigarrengo fase honetan, bi algoritmo diseinatu beharko dituzue, bata soluzio bakarrean oinarritutakoa, eta bestea poblazionala. Ez hori bakarrik, bi algoritmoetako batek operadore probabilistikoak erabili beharko ditu, Estimation of Distribution Algorithms (EDAk) edo Ant Colony Optimization (ACO)-ek egiten duten bezala. Algoritmoen helburua, komunitate kopuru jakin bat emanik, modularity maximizatzen duen komunitate banaketa (soluzioa) bilatzen saiatzea da.\n","\n","Errepasatu gaitegian zehar ikusi ditugun algoritmo guztiak, eta horiek kontuak izanik, libre zarete nahi dituzuen diseinuak sortzeko, baita ere hibridoak! Adi! Egiten duzuen aukeraketa argudiatu egin beharko duzue.\n","\n","\n","#### Entregablea\n","\n","Bigarrengo fasea ebaluatu ahal izateko, notebook honetan bertan algoritmoen diseinua eta implementazioa proposatu beharko duzue. Gogoratu algoritmo bat azaltzeko modurik errezena diagrama bat egitea dela. Adi! Atal bakoitzean hartutako erabakiak eta garatutako metodoak egoki argudiatu beharko dituzue. Ez argudiatzeak edo lana garaiz ez entregatzeak penalizazioa jasoko dute ebaluagarria den proiektuaren zati honetan. eGelan zehazten dira notebook-a igotzeko <b>egun eta orduak</b>.\n","\n","Momentuz, ez daukazue algoritmoen exekuzio eta konparaketak egin behar. Hirugarren fasean, esperimentazioaren inguruko baldintzak emango dizkizuet, eta, horrez gain, txostenaren idazketa burutu beharko duzue."]},{"cell_type":"markdown","metadata":{"id":"RjqfSpzifn97"},"source":["```python\r\n","## Hemendik aurrera, intuizioa da nagusi...\r\n","\r\n","Nire aukeraketa, UMDA bat swap-LS batekin eta metodo eraikitzaile batekin.\r\n","\r\n","Eta bestea, ILS bat, metodo eraikitzaile estokastiko batekin eta,\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"bAGTFJfYegbb"},"source":["## Grafoa sortu"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf0XhF2LD7GH","executionInfo":{"status":"ok","timestamp":1615651148419,"user_tz":-60,"elapsed":27155,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"f36cef62-2547-4acd-eb17-d930eccc179e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ow5jMgSPD828","executionInfo":{"status":"ok","timestamp":1615651148420,"user_tz":-60,"elapsed":27049,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"e0dc2cf8-e656-4293-dd86-a832c3d9bf2c"},"source":["%cd /content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/BH/Proiektua - Community Detection"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/Ingeniaritza Informatikoa/4. Maila/2. Lauhilekoa/BH/Proiektua - Community Detection'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bwpplowl6Tig","executionInfo":{"status":"ok","timestamp":1615651148421,"user_tz":-60,"elapsed":27044,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}},"outputId":"df2f7502-ae23-4da4-b732-8e2654ccb57f"},"source":["%cd /content/drive/MyDrive/Proiektua - Community Detection"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1YBawHqMJJ5PaYxHZNg5RnM4UIRU8tnJ7/Proiektua - Community Detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6vBmKoeYOov8","executionInfo":{"status":"ok","timestamp":1615651150232,"user_tz":-60,"elapsed":28853,"user":{"displayName":"Aitor Zubillaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38XZ32IvQ0Ma6HNMA2XtPZ_PiulROJrKdZHzejA=s64","userId":"01994148971300120890"}}},"source":["# SQL\r\n","import sqlite3\r\n","\r\n","# Pandas\r\n","import pandas as pd\r\n","\r\n","# Graph\r\n","import community\r\n","import networkx as nx\r\n","\r\n","# Plot\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","\r\n","# Combinations\r\n","import itertools\r\n","\r\n","def sortu_grafoa():\r\n","    # Get data\r\n","    connect = sqlite3.connect('data/database.sqlite')\r\n","    query = \"\"\"\r\n","    SELECT pa.paper_id, pa.author_id, a.name\r\n","    FROM paper_authors AS pa JOIN papers AS p ON pa.paper_id = p.id\r\n","    JOIN authors as a ON pa.author_id = a.id\r\n","    WHERE p.Year BETWEEN '2014' AND '2015'\r\n","    \"\"\"\r\n","    df = pd.read_sql(query, connect)\r\n","\r\n","    # Have a look at data\r\n","    df.head(10)\r\n","\r\n","    # Initialize graph\r\n","    G = nx.Graph()\r\n","\r\n","    # Transform\r\n","    # Autorearen IDa erabili beharrean erabili izena.\r\n","    for p, a in df.groupby('paper_id')['name']: \r\n","        for u, v in itertools.combinations(a, 2):\r\n","            if G.has_edge(u, v):\r\n","                G[u][v]['weight'] +=1\r\n","            else:\r\n","                G.add_edge(u, v, weight=1)\r\n","                \r\n","    # Print graph size\r\n","    print('Autore kopurua grafoan:', G.number_of_nodes())\r\n","    print('Elkarlan kopurua grafoan:', G.number_of_edges())\r\n","    \r\n","    return G\r\n","\r\n","def bistaratu_grafoa(G):\r\n","    plt.figure(figsize=(13, 9))\r\n","    pos = nx.spring_layout(G)\r\n","    nx.draw_networkx_nodes(G, pos, node_size = 20, node_color='0.75', label=True)\r\n","    nx.draw_networkx_edges(G, pos, alpha=0.5, width=1)\r\n","    plt.show()\r\n","\r\n","    plt.axis('off')\r\n","    plt.show()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS30qeNfZEYD"},"source":["G = sortu_grafoa()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8ZruenGZH7q"},"source":["bistaratu_grafoa(G)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2q6A1Ac_ep3N"},"source":["## Helburu-funtzioa"]},{"cell_type":"code","metadata":{"id":"AVUkmkTRfT1B"},"source":["import numpy as np\r\n","# 50 komunitate ausaz\r\n","soluzioa_1 = np.random.randint(50, size=1843)\r\n","# 10 komunitate ausaz\r\n","soluzioa_2 = np.random.randint(10, size=1843)\r\n","print(list(soluzioa_1))\r\n","print(list(soluzioa_2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAn8uFctq_uO"},"source":["import community\r\n","from collections import defaultdict\r\n","\r\n","### Helburu-funtzioa\r\n","def modularity(G, partition, weight='weight'):\r\n","    weights = defaultdict(float)\r\n","    degrees = defaultdict(float)\r\n","    sum = G.size(weight=weight)\r\n","    modularity = 0\r\n","\r\n","    for node in G:\r\n","        community = partition[node]\r\n","        degrees[community] += G.degree(node, weight=weight)\r\n","        for neighbour, data in G[node].items():\r\n","            if partition[neighbour] == community:\r\n","                if neighbour == node: # 4 nodes have self edges\r\n","                    weights[community] += data[weight] * 2\r\n","                else:\r\n","                    weights[community] += data[weight]\r\n","\r\n","    for community in set(partition.values()):\r\n","        modularity += (weights[community] / (2 * sum)) - (degrees[community] / (2 * sum)) ** 2\r\n","    return modularity\r\n","\r\n","## Gure inplementazioa\r\n","partition1 = dict(zip(G.nodes, soluzioa_1))\r\n","partition2 = dict(zip(G.nodes, soluzioa_2))\r\n","\r\n","print(\"Gure helburu-funtzioa:\")\r\n","print(\"1. soluzioaren modularitatea:\", modularity(G, partition1))\r\n","print(\"2. soluzioaren modularitatea:\", modularity(G, partition2))\r\n","print(\"Community moduluko modularity:\")\r\n","print(\"1. soluzioaren modularitatea:\", community.modularity(partition1, G))\r\n","print(\"2. soluzioaren modularitatea:\", community.modularity(partition2, G))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNlsZGjzt26P"},"source":["best_partition = community.best_partition(G)\r\n","print(\"Komunitate kopurua:\", max(best_partition.values())+1)\r\n","print(\"Soluzio onenaren modularitatea:\", community.modularity(best_partition, G))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIFvkXAGv5gw"},"source":["G2 = community.induced_graph(best_partition, G)\r\n","bistaratu_grafoa(G2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V6-rfeT29ZXS"},"source":["## Random Search"]},{"cell_type":"code","metadata":{"id":"lsY2Hm-69dMd"},"source":["def random_search(G, num_solutions, com_count):\r\n","    size = G.number_of_nodes()\r\n","    best_solution = list(np.random.randint(com_count, size=size))\r\n","    best_partition = dict(zip(G.nodes, best_solution))\r\n","    best_fitness = modularity(G, best_partition)\r\n","    for i in range(num_solutions-1):\r\n","        solution = list(np.random.randint(com_count, size=size))\r\n","        partition = dict(zip(G.nodes, best_solution))\r\n","        fitness = modularity(G, best_partition)\r\n","        if fitness > best_fitness:\r\n","            best_fitness = fitness\r\n","            best_solution = solution\r\n","    return (best_fitness, best_solution, num_solutions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F88Y4jhxdCCy"},"source":["## Libraries"]},{"cell_type":"markdown","metadata":{"id":"kvmWmay4dAn8"},"source":["Community library https://python-louvain.readthedocs.io/en/latest/\r\n","\r\n","https://github.com/taynaud/python-louvain/tree/master/community\r\n","\r\n","CDLib library https://cdlib.readthedocs.io/en/latest/"]},{"cell_type":"markdown","metadata":{"id":"Ica8uPHeVYVR"},"source":["## Constructive"]},{"cell_type":"markdown","metadata":{"id":"kfa_vLmpVbaF"},"source":["Fast unfolding of communities in large networks https://iopscience.iop.org/article/10.1088/1742-5468/2008/10/P10008/meta\r\n","\r\n","From Louvain to Leiden: guaranteeing well-connected communities https://www.nature.com/articles/s41598-019-41695-z"]},{"cell_type":"markdown","metadata":{"id":"_VwtQqCkUd4V"},"source":["## 1. Local Search"]},{"cell_type":"markdown","metadata":{"id":"c0GfSQdRVK9Z"},"source":["community detection local search https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=community+detection+local+search&oq=com\r\n","\r\n","An evolutionary method for community detection using a novel local search strategy https://www.sciencedirect.com/science/article/pii/S0378437119301402\r\n","\r\n","An iterated local search algorithm for community detection in complex networks https://www.worldscientific.com/doi/abs/10.1142/S0217979220500137\r\n","\r\n","A novel iterated greedy algorithm for detecting communities in complex network https://link.springer.com/content/pdf/10.1007/s13278-020-00641-y.pdf"]},{"cell_type":"markdown","metadata":{"id":"sqzxucuW9hVb"},"source":["### Swap"]},{"cell_type":"code","metadata":{"id":"JP-wOS_W3Kbf"},"source":["def swap(solution, i, j):\r\n","    solution[i], solution[j] = solution[j], solution[i]\r\n","    return solution\r\n","\r\n","def swap_neighbours(solution):\r\n","    neighbours = []\r\n","    size = len(solution)\r\n","    for i in range(size):\r\n","        for j in range(i+1, size):\r\n","            neighbours.append(swap(solution[:], i, j))\r\n","    return neighbours\r\n","\r\n","def best_first_swap(G, best_solution, best_fitness, evals, max_evals):\r\n","    improve = False\r\n","    size = len(best_solution)\r\n","    for i in range(size):\r\n","        for j in range(i+1, size):\r\n","            solution = swap(best_solution[:], i, j)\r\n","            partition = dict(zip(G.nodes, solution))\r\n","            fitness = modularity(G, partition)\r\n","            evals += 1\r\n","            if fitness > best_fitness:\r\n","                improve = True\r\n","                return (fitness, solution, evals, improve)\r\n","            if evals == max_evals:\r\n","                return (best_fitness, best_solution, evals, improve)\r\n","    return (best_fitness, best_solution, evals, improve)\r\n","\r\n","def local_search_swap(G, max_evals, com_count):\r\n","    size = G.number_of_nodes()\r\n","    best_solution = list(np.random.randint(com_count, size=size))\r\n","    #best_partition = dict(zip(G.nodes, best_solution))\r\n","    best_partition = community.best_partition(G)\r\n","    best_fitness = modularity(G, best_partition)\r\n","    improve = True\r\n","    evals = 1\r\n","    while evals < max_evals and improve:\r\n","        best_fitness, best_solution, evals, improve = best_first_swap(G, best_solution, best_fitness, evals, max_evals)\r\n","        \r\n","    return (best_fitness, best_solution, evals)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Px7MkI1i9jt3"},"source":["### Insert"]},{"cell_type":"code","metadata":{"id":"9sgKOlUe22m4"},"source":["def insert(solution, i, j):\r\n","    solution.insert(j, solution.pop(i))\r\n","    return solution\r\n","\r\n","def insert_neighbours(solution):\r\n","    neighbours = []\r\n","    size = len(solution)\r\n","    for i in range(size):\r\n","        for j in list(range(0, i-1)) + list(range(i+1, size)):\r\n","            neighbours.append(insert(solution[:], i, j))\r\n","    return neighbours\r\n","\r\n","def best_first_insert(G, best_solution, best_fitness, evals, max_evals):\r\n","    improve = False\r\n","    size = len(best_solution)\r\n","    for i in range(size):\r\n","        for j in list(range(0, i-1)) + list(range(i+1, size)):\r\n","            solution = insert(best_solution[:], i, j)\r\n","            partition = dict(zip(G.nodes, solution))\r\n","            fitness = modularity(G, partition)\r\n","            evals += 1\r\n","            if fitness > best_fitness:\r\n","                improve = True\r\n","                return (fitness, solution, evals, improve)\r\n","            if evals == max_evals:\r\n","                return (best_fitness, best_solution, evals, improve)\r\n","    return (best_fitness, best_solution, evals, improve)\r\n","\r\n","def local_search_insert(G, max_evals, com_count):\r\n","    size = G.number_of_nodes()\r\n","    best_solution = list(np.random.randint(com_count, size=size))\r\n","    best_partition = dict(zip(G.nodes, best_solution))\r\n","    best_fitness = modularity(G, best_partition)\r\n","    improve = True\r\n","    evals = 1\r\n","    while evals < max_evals and improve:\r\n","        best_fitness, best_solution, evals, improve = best_first_insert(G, best_solution, best_fitness, evals, max_evals)\r\n","        \r\n","    return (best_fitness, best_solution, evals)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dNvwiux4L6uc"},"source":["### Hamming"]},{"cell_type":"code","metadata":{"id":"0x5YUz9MOaZm"},"source":["def hamming(solution, i, cj):\r\n","    solution[i] = cj\r\n","    return solution\r\n","\r\n","def hamming_neighbours(solution, com_count):\r\n","    neighbours = []\r\n","    size = len(solution)\r\n","    for i in range(size):\r\n","        for cj in range(com_count):\r\n","            neighbours.append(hamming(solution[:], i, cj))\r\n","    return neighbours\r\n","\r\n","def best_first_hamming(G, best_solution, best_fitness, evals, max_evals, com_count):\r\n","    improve = False\r\n","    size = len(best_solution)\r\n","    for i in range(size):\r\n","        for j in range(com_count):\r\n","            solution = hamming(best_solution[:], i, j)\r\n","            partition = dict(zip(G.nodes, solution))\r\n","            fitness = modularity(G, partition)\r\n","            evals += 1\r\n","            if fitness > best_fitness:\r\n","                improve = True\r\n","                return (fitness, solution, evals, improve)\r\n","            if evals == max_evals:\r\n","                return (best_fitness, best_solution, evals, improve)\r\n","    return (best_fitness, best_solution, evals, improve)\r\n","\r\n","def local_search_hamming(G, max_evals, com_count):\r\n","    size = G.number_of_nodes()\r\n","    best_solution = list(np.random.randint(com_count, size=size))\r\n","    best_partition = dict(zip(G.nodes, best_solution))\r\n","    best_fitness = modularity(G, best_partition)\r\n","    improve = True\r\n","    evals = 1\r\n","    while evals < max_evals and improve:\r\n","        best_fitness, best_solution, evals, improve = best_first_hamming(G, best_solution, best_fitness, evals, max_evals, com_count)\r\n","        \r\n","    return (best_fitness, best_solution, evals)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BS45yYfZX1ry"},"source":["### Merge"]},{"cell_type":"code","metadata":{"id":"ALpW6Bq0X3mJ"},"source":["def merge(solution, ci, cj):\r\n","    # solution = np.where(solution == cj, ci)\r\n","    size = len(solution)\r\n","    for i in range(size):\r\n","        if solution[j] == cj:\r\n","            solution[j] = ci\r\n","    return solution\r\n","\r\n","def merge_neighbours(solution, com_count):\r\n","    neighbours = []\r\n","    for ci in range(com_count):\r\n","        for cj in range(com_count):\r\n","            neighbours.append(merge(solution[:], ci, cj))\r\n","    return neighbours"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DdF5mlmkRI4X"},"source":["### Simulated Annealing"]},{"cell_type":"code","metadata":{"id":"R_9FjK6LRNci"},"source":["import random\r\n","import math\r\n","\r\n","def initial_temperature(best_fitness):\r\n","    return 0.025 * best_fitness\r\n","\r\n","def update_temperature(temp):\r\n","    return 0.9 * temp\r\n","    \r\n","def simmulated_annealing(best_solution, best_fitness, solution, fitness, temp):\r\n","    if fitness > best_fitness:\r\n","        best_solution = solution\r\n","        best_fitness = fitness\r\n","    else:\r\n","        p = random.uniform(0, 1)\r\n","        if p <= math.exp((fitness - best_fitness) / temp):\r\n","            best_solution = solution\r\n","            best_fitness = fitness\r\n","    temp = update_temperature(temp)\r\n","    return best_solution, best_fitness, temp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXSTsp08-7KH"},"source":["## Local Search vs Random Search"]},{"cell_type":"code","metadata":{"id":"QTyePfwk_ITo"},"source":["import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import numpy as np\r\n","from tqdm import tqdm\r\n","import time as tm\r\n","\r\n","# Egin exekuzioak budget desberdinetarako: 10, 100, 1000, 10000...\r\n","def run_search(function, com_count, budget=5, repetitions=1):\r\n","    list_budget = []\r\n","    list_fit = []\r\n","    list_time = []\r\n","    for exp in range(1, budget):\r\n","        budget=10**exp\r\n","        avg_fit = 0\r\n","        avg_time = 0\r\n","        for rep in tqdm(range(repetitions), position=0, leave=True):\r\n","            start = tm.time()\r\n","            (fitness, sol, evals) = function(G, budget, com_count)\r\n","            end = tm.time()\r\n","            avg_time += end - start\r\n","            avg_fit += fitness\r\n","        avg_fit = avg_fit/repetitions\r\n","        avg_time = avg_time/repetitions\r\n","        print()\r\n","        print(\"Budget:\", budget, \" Average fitness:\", avg_fit, \" Average time:\", avg_time)\r\n","        list_budget.append(budget)\r\n","        list_fit.append(avg_fit)\r\n","        list_time.append(avg_time)\r\n","    return list_budget, list_fit, list_time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zTPvhxVP_aIz"},"source":["list_budget, list_fit_ls_swap, list_time_ls_swap = run_search(local_search_swap, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPhFnTdSA1z8"},"source":["list_budget, list_fit_ls_swap, list_time_ls_swap = run_search(local_search_swap, 50, budget=6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEzoLHp0yyO6"},"source":["list_budget, list_fit_ls_swap, list_time_ls_swap = run_search(local_search_swap, 250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnqwgetSzQMe"},"source":["list_budget, list_fit_ls_swap, list_time_ls_swap = run_search(local_search_swap, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bC2hQ97AFT5"},"source":["list_budget, list_fit_ls_swap, list_time_ls_swap = run_search(local_search_swap, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjMhrBHEFclj"},"source":["list_budget, list_fit_ls_ins, list_time_ls_ins = run_search(local_search_insert, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GdLOagUPd9Q"},"source":["list_budget, list_fit_ls_ham, list_time_ls_ham = run_search(local_search_hamming, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQNtDpdVApPQ"},"source":["list_budget, list_fit_rs, list_time_rs = run_search(random_search, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-reRjukm_uXn"},"source":["# Datuak gordetzeko egitura\r\n","datuak = pd.DataFrame({\"n\":list_budget,\"Local Swap\":list_fit_ls_swap,\"Local Insert\":list_fit_ls_ins,\"Local Hamming\":list_fit_ls_ham,\"Random Search\":list_fit_rs}) \r\n","print(datuak)\r\n","print()\r\n","\r\n","#Irudikatu emaitzak plot batean.\r\n","ax = plt.gca()\r\n","datuak.plot(kind='line',x='n',y='Local Swap',ax=ax)\r\n","datuak.plot(kind='line',x='n',y='Local Insert',ax=ax)\r\n","datuak.plot(kind='line',x='n',y='Local Hamming',ax=ax)\r\n","datuak.plot(kind='line',x='n',y='Random Search', color='red', ax=ax,title='Local Search vs. Random Search')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pn_ufuaMUlHk"},"source":["## 2. EDA"]},{"cell_type":"markdown","metadata":{"id":"OKcAchN1rw7X"},"source":["community detection eda https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=community+detection+eda&btnG=\r\n","\r\n","An EDA-based Community Detection in Complex\r\n","Networks http://webpages.iust.ac.ir/mozayani/Papers-pdf/ieee79189c24-5f04-20150417114429.pdf\r\n","\r\n","The Improved Estimation of Distribution Algorithms for Community Detection https://ieeexplore.ieee.org/abstract/document/8711535\r\n","\r\n","https://github.com/DEAP/deap/tree/master/examples/eda\r\n","\r\n","http://deap.gel.ulaval.ca/doc/default/examples/eda.html"]},{"cell_type":"code","metadata":{"id":"orSnngF0vsnM"},"source":["com_count = 10\r\n","num_individuals = 10\r\n","size = G.number_of_nodes()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KREV1qatxbNq"},"source":["def random_population(num_individuals, size):\r\n","    population = np.zeros((num_individuals, size), dtype=int)\r\n","    for i in range(num_individuals):\r\n","        solution = np.random.randint(com_count, size=size)\r\n","        population[i] = solution\r\n","    return population\r\n","\r\n","population = random_population(num_individuals, size)\r\n","print(population)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KliOEB44Uj4V"},"source":["def louvain_population(num_individuals, size):\r\n","    population = np.zeros((num_individuals, size), dtype=int)\r\n","    for i in range(num_individuals):\r\n","        partition = community.best_partition(G)\r\n","        solution = np.fromiter(partition.values(), dtype=int)\r\n","        population[i] = solution\r\n","    return population\r\n","\r\n","louvain_pop = louvain_population(num_individuals, size)\r\n","print(louvain_pop)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tt6zABgkzxEK"},"source":["def get_distribution(population, com_count):\r\n","    num_individuals = population.shape[0]\r\n","    size = population.shape[1]\r\n","    distribution = np.zeros((com_count, size), dtype=float)\r\n","    num_individuals = len(population)\r\n","    for individual in population:\r\n","        for i, com in enumerate(individual):\r\n","            distribution[com, i] += 1 / num_individuals\r\n","    return distribution\r\n","\r\n","distribution = get_distribution(population, com_count)\r\n","print(distribution)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlF121yBF0gE"},"source":["def cummulative_distribution(population, com_count):\r\n","    num_individuals = population.shape[0]\r\n","    size = population.shape[1]\r\n","    distribution = np.zeros((com_count, size), dtype=float)\r\n","    for individual in population:\r\n","        for i, com in enumerate(individual):\r\n","            for j in range(com, com_count):\r\n","                distribution[j, i] += 1 / num_individuals\r\n","    return distribution\r\n","    \r\n","cum_distribution = cummulative_distribution(population, com_count)\r\n","print(cum_distribution)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TL4HGk_3AXPh"},"source":["def solution_modularity(solution):\r\n","    partition = dict(zip(G.nodes, solution))\r\n","    return modularity(G, partition)\r\n","\r\n","def select_best(population):\r\n","    num_individuals = population.shape[0]\r\n","    size = population.shape[1]\r\n","    k = int(num_individuals / 2)\r\n","    sorted_pop = np.zeros((k, size), dtype=int)\r\n","    sorted_pop = np.array(sorted(population, key=solution_modularity, reverse=True))\r\n","    best = sorted_pop[:k]\r\n","    return best\r\n","\r\n","def tournament_selection(population, tournaments=5):\r\n","    size = population.shape[1]\r\n","    num_individuals = population.shape[0]\r\n","    tournament_size = int(num_individuals / 2)\r\n","    winners = np.zeros((tournaments, size), dtype=int)\r\n","    for i in range(tournaments):\r\n","        solutions = random.choices(population, k=tournament_size)\r\n","        solutions = np.array(sorted(solutions, key=solution_modularity, reverse=True))\r\n","        winners[i] = solutions[0]\r\n","    return winners\r\n","\r\n","selected = select_best(population)\r\n","print(selected)\r\n","selected = tournament_selection(population)\r\n","print(selected)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"doEcEfnu-O-x"},"source":["def generate_solution(distribution, num_individuals):\r\n","    com_count = distribution.shape[0]\r\n","    size = distribution.shape[1]\r\n","    solution = np.zeros(size, dtype=int)\r\n","    for i in range(size):\r\n","        r = random.uniform(0, 1)\r\n","        for j in range(com_count-1):\r\n","            if j == 0 and distribution[j][i] > r:\r\n","                solution[i] = j\r\n","                break\r\n","            elif distribution[j][i] <= r and distribution[j+1][i] > r:\r\n","                solution[i] = j+1\r\n","                break\r\n","    return solution\r\n","\r\n","generated_solution = generate_solution(cum_distribution, num_individuals)\r\n","print(generated_solution[:20])\r\n","print(solution_modularity(generated_solution))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQ-LF5UGQyCY"},"source":["def generate_population(distribution, num_individuals):\r\n","    com_count = distribution.shape[0]\r\n","    size = distribution.shape[1]\r\n","    population = np.zeros((num_individuals, size), dtype=int)\r\n","    for i in range(size):\r\n","        randoms = np.random.uniform(size=num_individuals)\r\n","        for k, r in enumerate(randoms):\r\n","            for j in range(com_count-1):\r\n","                if j == 0 and distribution[j][i] > r:\r\n","                    population[k][i] = j\r\n","                    break\r\n","                elif distribution[j][i] <= r and distribution[j+1][i] > r:\r\n","                    population[k][i] = j+1\r\n","                    break\r\n","    return population\r\n","\r\n","generated_population = generate_population(cum_distribution, num_individuals)\r\n","print(generated_population)\r\n","print(solution_modularity(generated_population[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHK_Pxh6e84z"},"source":["from tqdm import tqdm\r\n","com_count = 290\r\n","num_individuals = 20\r\n","def UMDA(G, max_evals, com_count, num_individuals):\r\n","    size = G.number_of_nodes()\r\n","    # population = random_population(num_individuals, size)\r\n","    population = louvain_population(num_individuals, size)\r\n","    evals = 0\r\n","    for i in tqdm(range(max_evals)):\r\n","        best = select_best(population)\r\n","        cum_distribution = cummulative_distribution(best, com_count)\r\n","        population = generate_population(cum_distribution, num_individuals)\r\n","        evals += 1\r\n","    sorted_population = np.array(sorted(population, key=solution_modularity, reverse=True))\r\n","    best_solution = sorted_population[0]\r\n","    best_fitness = solution_modularity(best_solution)\r\n","    return best_fitness, best_solution, evals"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nS6mWDNBXhWf"},"source":["best_fitness, best_solution, evals = UMDA(G, 5, com_count, num_individuals)\r\n","print(best_fitness)\r\n","print(best_solution[:30])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQHY-oaXpAvG"},"source":["## ACO"]},{"cell_type":"markdown","metadata":{"id":"ZT27bf-Yo_2k"},"source":["community detection aco https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=community+detection+aco&btnG=\r\n","\r\n","An adaptive population control framework for ACO-based community detection https://www.sciencedirect.com/science/article/pii/S0960077920302861"]}]}